{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we attempt to build our baseline.\n",
    "\n",
    "There are a lot of different built-in packages that can help us build a recommender system. For our baseline construction, we are using the `Surprise` package, which has a few different algorithms built in.\n",
    "\n",
    "We need to load in a custom dataset for `Surprise`. Based on the documentation, we just need to make sure our data frame has three columns: the user id, the item id, and the rating. Additionally, we'll need to specify the rating scale. In our case, users can rate a product discretely from 1 to 5.\n",
    "\n",
    "The `Surprise` package also provides methods for the training-testing data splitting, which could be of our use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from surprise import accuracy\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "reviews = pd.read_csv('preprocessed.csv')\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(reviews[['customer_id', 'product_id', 'star_rating']], reader)\n",
    "train_set, test_set = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly, baseline estimates consider the average rating an item receives across the entire dataset, as well as the average rating given by a particular user. Some items may receive much higher ratings than others, and some users may give more critical ratings. These variations are used in our baseline estimates to predict a score.\n",
    "\n",
    "To compute baseline estimates, two popular algorithms are Stochastic Gradient Descent (SGD) and Alternating Least Squares (ALS). In this instance, ALS would be adopted, which is a commonly used algorithm for collaborative filtering.\n",
    "\n",
    "GridSearchCV would be employed to identify optimal parameters, but more computational resources or additional time could improve its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2418786306124092 {'bsl_options': {'method': 'als', 'n_epochs': 14, 'reg_u': 16, 'reg_i': 15}}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.prediction_algorithms.baseline_only import BaselineOnly\n",
    "import random\n",
    "\n",
    "param_grid = {'bsl_options': {'method': ['als'],\n",
    "                             'n_epochs': random.sample(range(10, 20), 5),\n",
    "                             'reg_u': random.sample(range(10, 30), 5),\n",
    "                             'reg_i': random.sample(range(10, 30), 5)}}\n",
    "\n",
    "gs = GridSearchCV(BaselineOnly, param_grid, measures=['RMSE', 'MAE'], cv=5, n_jobs = -1)\n",
    "gs.fit(data)\n",
    "print(gs.best_score['rmse'], gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2409841103484036"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = BaselineOnly(bsl_options={'method': 'als', 'n_epochs': 14, 'reg_u': 16, 'reg_i': 15})\n",
    "fit = baseline.fit(train_set)\n",
    "predictions = fit.test(test_set)\n",
    "accuracy.rmse(predictions, verbose=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we could roughly build a preliminary \"Recommendation\" System.\n",
    "There is a written function we can use among the `Surprise` documentations to get the top-N recommendations for each user (https://surprise.readthedocs.io/en/stable/FAQ.html#how-to-get-the-top-n-recommendations-for-each-user).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "\n",
    "top_n = get_top_n(predictions, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B009DRP9RU', 4.03243074351026),\n",
       " ('B0043ZWQWI', 4.018181078562333),\n",
       " ('B004JKBEUM', 4.013568309771048),\n",
       " ('B0043ZYMP2', 4.009889495014582),\n",
       " ('B000FV8PTM', 3.9994831839353524),\n",
       " ('B003P1QDL6', 3.969674531673862),\n",
       " ('B002WJIQA8', 3.9067737247645327),\n",
       " ('B0044XDZII', 3.9045231337715585),\n",
       " ('B005MKGOOY', 3.88496863830129),\n",
       " ('B001QFYKMW', 3.8682906142917846)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n[reviews.customer_id[1]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, as our feature space is quite sparse, the baseline system cannot always submit the \"top-10\" recommendations, as there is a large number of customers who have only rated one product, as well as many products that have only one rating. This issue would be examined in our future work later in the Final."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
